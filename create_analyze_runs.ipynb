{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "    1. Decreasing stepsize in FW (-1 for rho/gamma)\n",
    "    2. Full dataset training (deterministic FW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMALL setting\n",
    "common = {'image_side': 10, 'giveup': 100, 'accuracy_threshold': 0.0, 'repetitions': 1}\n",
    "param_groups = {\n",
    "    'sgd':\n",
    "    [{'optimizer': 'sgd', 'train_batch_size': 1000, 'learning_rate': 0.1, 'epochs': 100, **common}],\n",
    "    \n",
    "    'frankwolfe':\n",
    "    [{'optimizer': 'frankwolfe', 'train_batch_size': 1000, 'p': 2.0, 'R': 100.0, 'gamma': 0.01, 'ro': 0.6,\n",
    "     'epochs': 200, **common}],\n",
    "    \n",
    "    'adam':\n",
    "    [{'optimizer': 'adam', 'train_batch_size': 1000, 'p': 2.0, 'learning_rate': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08,\n",
    "     'epochs': 200, **common}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medium setting\n",
    "common = {'image_side': 5, 'giveup': 100, 'accuracy_threshold': 0, 'p': 3.0, 'repetitions': 3}\n",
    "param_groups = {\n",
    "    'sgd':\n",
    "    [{'optimizer': 'sgd', 'train_batch_size': 1000, 'learning_rate': lr, 'epochs': 100, **common}\n",
    "     for lr in [0.1, 0.01, 0.001, 0.0001]],\n",
    "    \n",
    "    'frankwolfe':\n",
    "    [{'optimizer': 'frankwolfe', 'train_batch_size': 1000, 'R': 20, 'gamma': gamma, 'ro': ro,\n",
    "     'epochs': 100, **common} for gamma in [-1] + list(np.linspace(0, 1, 3))\n",
    "     for ro in [-1] + list(np.linspace(0, 1, 3))],\n",
    "    \n",
    "    'adam':\n",
    "    [{'optimizer': 'adam', 'train_batch_size': 1000, 'learning_rate': lr, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08,\n",
    "     'epochs': 100, **common} for lr in [0.1, 0.01, 0.001, 0.0001]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [x for group in param_groups.values() for x in group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sgd': ['learning_rate'], 'frankwolfe': ['gamma', 'ro'], 'adam': ['learning_rate']}\n"
     ]
    }
   ],
   "source": [
    "def varying_for_optim(d):\n",
    "    \"\"\" What changes for optimizer? \"\"\"\n",
    "    d0 = d[0]\n",
    "    keys = set()\n",
    "    for v in d:\n",
    "        for key, val in v.items():\n",
    "            if d0[key] != val:\n",
    "                keys.add(key)\n",
    "    return list(keys)\n",
    "\n",
    "# group -> what changes\n",
    "varying = {group: varying_for_optim(param_groups[group]) for group in param_groups.keys()}\n",
    "\n",
    "print(varying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nice(y):\n",
    "    if isinstance(y, float):\n",
    "        return str(round(y, 10))#'%.2g' % y\n",
    "    return str(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_one(**kwargs):\n",
    "    print('python experiment.py ' + \" \".join(['--' + x + ' ' + print_nice(y) for x, y in kwargs.items()]) + ' &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments in the correct order\n",
    "\n",
    "f = open('experiment.py', 'r').readlines()\n",
    "\n",
    "args_in_order = []\n",
    "for l in f:\n",
    "    k = 'parser.add_argument(\\'--'\n",
    "    if l.startswith(k):\n",
    "        args_in_order.append(l[len(k):].split('\\'')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file(**kwargs):\n",
    "    return (\"_\".join([x + '-' + print_nice(kwargs[x] if x in kwargs else None) for x in args_in_order])+'.output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python experiment.py --optimizer sgd --train_batch_size 1000 --learning_rate 0.1 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "sleep 5\n",
      "python experiment.py --optimizer sgd --train_batch_size 1000 --learning_rate 0.01 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "python experiment.py --optimizer sgd --train_batch_size 1000 --learning_rate 0.001 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "sleep 5\n",
      "python experiment.py --optimizer sgd --train_batch_size 1000 --learning_rate 0.0001 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "python experiment.py --optimizer frankwolfe --train_batch_size 1000 --R 20 --gamma -1 --ro -1 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "sleep 5\n",
      "python experiment.py --optimizer frankwolfe --train_batch_size 1000 --R 20 --gamma -1 --ro 0.0 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "python experiment.py --optimizer frankwolfe --train_batch_size 1000 --R 20 --gamma -1 --ro 0.5 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "sleep 5\n",
      "python experiment.py --optimizer frankwolfe --train_batch_size 1000 --R 20 --gamma -1 --ro 1.0 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "python experiment.py --optimizer frankwolfe --train_batch_size 1000 --R 20 --gamma 0.0 --ro -1 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "sleep 5\n",
      "python experiment.py --optimizer frankwolfe --train_batch_size 1000 --R 20 --gamma 0.0 --ro 0.0 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "python experiment.py --optimizer frankwolfe --train_batch_size 1000 --R 20 --gamma 0.0 --ro 0.5 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "sleep 5\n",
      "python experiment.py --optimizer frankwolfe --train_batch_size 1000 --R 20 --gamma 0.0 --ro 1.0 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "python experiment.py --optimizer frankwolfe --train_batch_size 1000 --R 20 --gamma 0.5 --ro -1 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "sleep 5\n",
      "python experiment.py --optimizer frankwolfe --train_batch_size 1000 --R 20 --gamma 0.5 --ro 0.0 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "python experiment.py --optimizer frankwolfe --train_batch_size 1000 --R 20 --gamma 0.5 --ro 0.5 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "sleep 5\n",
      "python experiment.py --optimizer frankwolfe --train_batch_size 1000 --R 20 --gamma 0.5 --ro 1.0 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "python experiment.py --optimizer frankwolfe --train_batch_size 1000 --R 20 --gamma 1.0 --ro -1 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "sleep 5\n",
      "python experiment.py --optimizer frankwolfe --train_batch_size 1000 --R 20 --gamma 1.0 --ro 0.0 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "python experiment.py --optimizer frankwolfe --train_batch_size 1000 --R 20 --gamma 1.0 --ro 0.5 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "sleep 5\n",
      "python experiment.py --optimizer frankwolfe --train_batch_size 1000 --R 20 --gamma 1.0 --ro 1.0 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "python experiment.py --optimizer adam --train_batch_size 1000 --learning_rate 0.1 --beta1 0.9 --beta2 0.999 --epsilon 1e-08 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "sleep 5\n",
      "python experiment.py --optimizer adam --train_batch_size 1000 --learning_rate 0.01 --beta1 0.9 --beta2 0.999 --epsilon 1e-08 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "python experiment.py --optimizer adam --train_batch_size 1000 --learning_rate 0.001 --beta1 0.9 --beta2 0.999 --epsilon 1e-08 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "sleep 5\n",
      "python experiment.py --optimizer adam --train_batch_size 1000 --learning_rate 0.0001 --beta1 0.9 --beta2 0.999 --epsilon 1e-08 --epochs 100 --image_side 5 --giveup 100 --accuracy_threshold 0 --p 3.0 --repetitions 3 &\n",
      "Total runs:  24\n",
      "Total time:  54.0\n"
     ]
    }
   ],
   "source": [
    "it = 0\n",
    "for params in parameters:\n",
    "    print_one(**params)\n",
    "    if it % 2 == 0:\n",
    "        print('sleep 5')\n",
    "    it += 1\n",
    "it = len(parameters)\n",
    "print('Total runs: ', it)\n",
    "print('Total time: ', common['repetitions'] * 3 * it / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_of_dicts_to_dict_of_arrays(arr):\n",
    "    \"\"\" Array of dicts to dict of arrays \"\"\"\n",
    "    all_keys = arr[0].keys()\n",
    "    return {key: [v[key] for v in arr] for key in all_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dict(d, do_plot = True, use_random = True):\n",
    "    \"\"\" Process one dictionary from  file, return key metrics or plot them \"\"\"\n",
    "    d0 = d\n",
    "    d = arr_of_dicts_to_dict_of_arrays(d)\n",
    "    all_keys = d.keys()\n",
    "    metrics = d\n",
    "    #print(metrics)\n",
    "    name = '0'\n",
    "    \n",
    "    if \n",
    "    \n",
    "    results = {key: [] for key in all_keys}\n",
    "    results['hessian_eigens_mean'] = []\n",
    "    results['hessian_eigens_max'] = []\n",
    "    del results['hessian_eigens']\n",
    "    \n",
    "    for i in range(len(d0)):\n",
    "        for key, val in metrics.items():\n",
    "            if key == 'hessian_eigens':\n",
    "                eigens = val[i]\n",
    "                results['hessian_eigens_mean'].append(np.mean(eigens))\n",
    "                results['hessian_eigens_max'].append(np.max(eigens))\n",
    "            elif isinstance(val[i], list):\n",
    "                results[key].append(val[i][-1]) # appending LAST loss/accuracy\n",
    "            else:\n",
    "                results[key].append(val[i])\n",
    "    \n",
    "    if do_plot:\n",
    "        fig, ax1 = plt.subplots()\n",
    "        ax2 = ax1.twinx()\n",
    "        \n",
    "        ax1.set_xlabel('epochs')\n",
    "        ax1.set_ylabel('loss', color='b')\n",
    "        ax1.tick_params('y', colors='b')\n",
    "        \n",
    "        ax2.set_ylabel('accuracy', color='r')\n",
    "        ax2.tick_params('y', colors='r')\n",
    "        \n",
    "        for i in range(len(d0)):\n",
    "            ax1.plot(metrics['train_loss'][i], label = 'train_loss')\n",
    "            ax1.plot(metrics['test_loss'][i], label = 'test_loss')\n",
    "\n",
    "            ax2.plot(metrics['train_acc'][i], label = 'train_acc')\n",
    "            ax2.plot(metrics['train_acc'][i], label = 'train_acc')\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig.legend()\n",
    "        plt.savefig('figures/' + name + '.eps', bbox_inches = 'tight')\n",
    "        plt.show()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(f, do_plot = False):\n",
    "    \"\"\" Process one file \"\"\"\n",
    "    if not os.path.isfile(f):\n",
    "        print('File ' + f + ' missing')\n",
    "        return\n",
    "    \n",
    "    content = open(f, 'r').read()\n",
    "    if content.startswith('Nothing['):\n",
    "        print('File ' + f + \" is empty\")\n",
    "        return\n",
    "    d = eval(content)\n",
    "    return process_dict(d, do_plot)\n",
    "    #return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter id -> processed file\n",
    "params_to_processed = [process_file(get_file(**param), do_plot = False) for param in parameters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer': 'sgd', 'train_batch_size': 1000, 'learning_rate': 0.1, 'epochs': 100, 'image_side': 10, 'giveup': 100, 'accuracy_threshold': 0.0, 'repetitions': 1}\n",
      "{'train_loss': [1.8829033], 'test_loss': [1.8760109], 'train_acc': [0.61038333], 'test_acc': [0.6179], 'hessian_eigens_mean': [0.000596617091062123], 'hessian_eigens_max': [0.6542341]}\n",
      "{'optimizer': 'frankwolfe', 'train_batch_size': 1000, 'p': 2.0, 'R': 100.0, 'gamma': 0.01, 'ro': 0.6, 'epochs': 200, 'image_side': 10, 'giveup': 100, 'accuracy_threshold': 0.0, 'repetitions': 1}\n",
      "{'train_loss': [1.8721464], 'test_loss': [1.8653136], 'train_acc': [0.61845], 'test_acc': [0.6254], 'hessian_eigens_mean': [0.0003984750364007894], 'hessian_eigens_max': [0.4615565]}\n",
      "{'optimizer': 'adam', 'train_batch_size': 1000, 'p': 2.0, 'learning_rate': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08, 'epochs': 200, 'image_side': 10, 'giveup': 100, 'accuracy_threshold': 0.0, 'repetitions': 1}\n",
      "{'train_loss': [1.4957184], 'test_loss': [1.5014652], 'train_acc': [0.9698167], 'test_acc': [0.963], 'p_norm': [101.4558], 'hessian_eigens_mean': [0.0006790847303972931], 'hessian_eigens_max': [0.8046694]}\n"
     ]
    }
   ],
   "source": [
    "for param in parameters:\n",
    "    print(param)\n",
    "    fs = process_file(get_file(**param))\n",
    "    print(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train_loss': [1.8829033],\n",
       "  'test_loss': [1.8760109],\n",
       "  'train_acc': [0.61038333],\n",
       "  'test_acc': [0.6179],\n",
       "  'hessian_eigens_mean': [0.000596617091062123],\n",
       "  'hessian_eigens_max': [0.6542341]},\n",
       " {'train_loss': [1.8721464],\n",
       "  'test_loss': [1.8653136],\n",
       "  'train_acc': [0.61845],\n",
       "  'test_acc': [0.6254],\n",
       "  'hessian_eigens_mean': [0.0003984750364007894],\n",
       "  'hessian_eigens_max': [0.4615565]},\n",
       " {'train_loss': [1.4957184],\n",
       "  'test_loss': [1.5014652],\n",
       "  'train_acc': [0.9698167],\n",
       "  'test_acc': [0.963],\n",
       "  'p_norm': [101.4558],\n",
       "  'hessian_eigens_mean': [0.0006790847303972931],\n",
       "  'hessian_eigens_max': [0.8046694]}]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_metric(summary):\n",
    "    \"\"\" Summary of one element in params_to_processed[], a number\n",
    "    Using mean test accuracy over runs\n",
    "    \"\"\"\n",
    "    return np.mean(summary['test_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_to_result(param):\n",
    "    \"\"\" Parameter setting to results summary \"\"\"\n",
    "    idx = parameters.index(param)\n",
    "    return params_to_processed[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best(optim):\n",
    "    \"\"\" Select best parameters for an optimizer \"\"\"\n",
    "    \n",
    "    metrics = [selection_metric(param_to_result(p)) for p in param_groups[optim]]\n",
    "    best_idx = np.argmax(metrics)\n",
    "    return parameters.index(param_groups[optim][best_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_best('adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
